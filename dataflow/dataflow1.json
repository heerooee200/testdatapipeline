{
	"name": "dataflow1",
	"properties": {
		"type": "MappingDataFlow",
		"typeProperties": {
			"sources": [
				{
					"linkedService": {
						"referenceName": "DLCadenasLinkedService",
						"type": "LinkedServiceReference"
					},
					"name": "archivo"
				}
			],
			"sinks": [
				{
					"name": "sink1"
				}
			],
			"transformations": [
				{
					"name": "MapDrifted1",
					"description": "Creates an explicit mapping for each drifted column"
				},
				{
					"name": "Aggregate1"
				}
			],
			"script": "parameters{\n\tpath_file as string\n}\nsource(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tignoreNoFilesFound: false,\n\tformat: 'delimited',\n\tfileSystem: 'files',\n\tfileName: 'df2.csv',\n\tcolumnDelimiter: ';',\n\tescapeChar: '\\\\',\n\tqutoChar: '\\\"',\n\tcolumnNamesAsHeader: true) ~> archivo\narchivo derive(sku_cadena = toString(byName('sku_cadena')),\n\t\tventa_clp_dia = toString(byName('venta_clp_dia')),\n\t\tventa_unidades_dia = toString(byName('venta_unidades_dia')),\n\t\tstock = toString(byName('stock')),\n\t\tfecha = toString(byName('fecha')),\n\t\tcadena = toString(byName('cadena'))) ~> MapDrifted1\nMapDrifted1 aggregate(groupBy(cadena),\n\tcadena_count = count()) ~> Aggregate1\nAggregate1 sink(allowSchemaDrift: true,\n\tvalidateSchema: false,\n\tpartitionFileNames:['archivojson'],\n\tskipDuplicateMapInputs: true,\n\tskipDuplicateMapOutputs: true,\n\tstore: 'cache',\n\tformat: 'inline',\n\toutput: true,\n\tsaveOrder: 0,\n\tpartitionBy('hash', 1)) ~> sink1"
		}
	}
}